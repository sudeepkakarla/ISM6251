{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxGJbLsUhuc8"
   },
   "source": [
    "# Week05 -\n",
    "\n",
    "In this week we look at using ensembles of models to improve the performance of our models. We will look at the following:\n",
    "\n",
    "* RandomForest\n",
    "* AdaBoost\n",
    "* Gradiant Boosting\n",
    "* XG Boosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tuXRZKEYrDa"
   },
   "source": [
    "## Introduction and Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q08EVUytY3eh"
   },
   "source": [
    "In this notebook, we will reuse the Universal Bank dataset.\n",
    "\n",
    "This time, we are developing a model to predict whether a customer will accept a personal loan offer. The dataset contains 5000 observations and 14 variables. The data is available on one of my GitHub repos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmYLcm3aY8X5"
   },
   "source": [
    "## Install and import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 23.1.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/sudeepkakarla/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB\n",
      "    libxgboost-1.5.0           |       he9d5cce_2         1.2 MB\n",
      "    py-xgboost-1.5.0           |   py39hecd8cb5_2         154 KB\n",
      "    xgboost-1.5.0              |   py39hecd8cb5_2          15 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  pkgs/main/osx-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  libxgboost         pkgs/main/osx-64::libxgboost-1.5.0-he9d5cce_2\n",
      "  py-xgboost         pkgs/main/osx-64::py-xgboost-1.5.0-py39hecd8cb5_2\n",
      "  xgboost            pkgs/main/osx-64::xgboost-1.5.0-py39hecd8cb5_2\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "libxgboost-1.5.0     | 1.2 MB    | ##################################### | 100% \n",
      "xgboost-1.5.0        | 15 KB     | ##################################### | 100% \n",
      "py-xgboost-1.5.0     | 154 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "# You may need to install xgboost (it's not part of the sklearn package)\n",
    "!conda install xgboost -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8zNdljvIhuc8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGgrXNQPZT3J"
   },
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "q3u5LsGyhudA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://github.com/timcsmith/MIS536-Public/raw/master/Data/UniversalBank.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aOH_GFGZZFx"
   },
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "OkUM_mnHhudC",
    "outputId": "b4e542fe-5d03-4602-e4d9-06a6d0e7c65d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
      "0   1   25           1      49     91107       4    1.6          1         0   \n",
      "1   2   45          19      34     90089       3    1.5          1         0   \n",
      "2   3   39          15      11     94720       1    1.0          1         0   \n",
      "3   4   35           9     100     94112       1    2.7          2         0   \n",
      "4   5   35           8      45     91330       4    1.0          2         0   \n",
      "\n",
      "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
      "0              0                   1           0       0           0  \n",
      "1              0                   1           0       0           0  \n",
      "2              0                   0           0       0           0  \n",
      "3              0                   0           0       0           0  \n",
      "4              0                   0           0       0           1  \n",
      "Index(['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
      "       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n",
      "       'CD Account', 'Online', 'CreditCard'],\n",
      "      dtype='object')\n",
      "                ID          Age   Experience       Income      ZIP Code  \\\n",
      "count  5000.000000  5000.000000  5000.000000  5000.000000   5000.000000   \n",
      "mean   2500.500000    45.338400    20.104600    73.774200  93152.503000   \n",
      "std    1443.520003    11.463166    11.467954    46.033729   2121.852197   \n",
      "min       1.000000    23.000000    -3.000000     8.000000   9307.000000   \n",
      "25%    1250.750000    35.000000    10.000000    39.000000  91911.000000   \n",
      "50%    2500.500000    45.000000    20.000000    64.000000  93437.000000   \n",
      "75%    3750.250000    55.000000    30.000000    98.000000  94608.000000   \n",
      "max    5000.000000    67.000000    43.000000   224.000000  96651.000000   \n",
      "\n",
      "            Family        CCAvg    Education     Mortgage  Personal Loan  \\\n",
      "count  5000.000000  5000.000000  5000.000000  5000.000000    5000.000000   \n",
      "mean      2.396400     1.937938     1.881000    56.498800       0.096000   \n",
      "std       1.147663     1.747659     0.839869   101.713802       0.294621   \n",
      "min       1.000000     0.000000     1.000000     0.000000       0.000000   \n",
      "25%       1.000000     0.700000     1.000000     0.000000       0.000000   \n",
      "50%       2.000000     1.500000     2.000000     0.000000       0.000000   \n",
      "75%       3.000000     2.500000     3.000000   101.000000       0.000000   \n",
      "max       4.000000    10.000000     3.000000   635.000000       1.000000   \n",
      "\n",
      "       Securities Account  CD Account       Online   CreditCard  \n",
      "count         5000.000000  5000.00000  5000.000000  5000.000000  \n",
      "mean             0.104400     0.06040     0.596800     0.294000  \n",
      "std              0.305809     0.23825     0.490589     0.455637  \n",
      "min              0.000000     0.00000     0.000000     0.000000  \n",
      "25%              0.000000     0.00000     0.000000     0.000000  \n",
      "50%              0.000000     0.00000     1.000000     0.000000  \n",
      "75%              0.000000     0.00000     1.000000     1.000000  \n",
      "max              1.000000     1.00000     1.000000     1.000000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "# read the first row of the dataset \n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "print(df.describe())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiaaNFX2Zf-I"
   },
   "source": [
    "## Clean/transform data (where necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "3JuJlVGDkINJ",
    "outputId": "082781c3-db3c-44e8-a7fd-ba35f35cbbfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
       "       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n",
       "       'CD Account', 'Online', 'CreditCard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on findings from data exploration, we need to clean up colum names, as there are some leading whitespace characters\n",
    "df.columns = [s.strip() for s in df.columns] \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the columns we are not using as predictors (see previous notebooks -- we are given a subset of input variables to consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID', 'ZIP Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "      <th>Edu_2</th>\n",
       "      <th>Edu_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Experience  Income  Family  CCAvg  Mortgage  Personal Loan  \\\n",
       "0   25           1      49       4    1.6         0              0   \n",
       "1   45          19      34       3    1.5         0              0   \n",
       "2   39          15      11       1    1.0         0              0   \n",
       "\n",
       "   Securities Account  CD Account  Online  CreditCard  Edu_2  Edu_3  \n",
       "0                   1           0       0           0      0      0  \n",
       "1                   1           0       0           0      0      0  \n",
       "2                   0           0       0           0      0      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# translation education categories into dummy vars\n",
    "df = df.join(pd.get_dummies(df['Education'], prefix='Edu', drop_first=True))\n",
    "df.drop('Education', axis=1, inplace = True)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKY30W1pZxCP"
   },
   "source": [
    "## Split data intro training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "d0fAfB0ThudG",
    "outputId": "47f231af-3781-4603-95b8-d9a1fca0236e"
   },
   "outputs": [],
   "source": [
    "# construct datasets for analysis\n",
    "target = 'Personal Loan'\n",
    "predictors = list(df.columns)\n",
    "predictors.remove(target)\n",
    "X = df[predictors]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "t0DkCAoChudI",
    "outputId": "4f5824b6-d5e0-419c-c916-6be218916af2"
   },
   "outputs": [],
   "source": [
    "# create the training set and the test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2A_u7rQhuc_"
   },
   "source": [
    "## Prediction with Decision Tree (using default parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30gNRdX-qtNT"
   },
   "source": [
    "You can find details about SKLearm's DecisionTree classifier [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbPfUmcEXf6K"
   },
   "source": [
    "Create a decision tree using all of the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UZ60Vn1AhudK"
   },
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntgxBhvJXkjp"
   },
   "source": [
    "Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "xPL4rRlVhudM",
    "outputId": "db26a1f0-23c9-4a02-87c5-34e3dbd71ccf"
   },
   "outputs": [],
   "source": [
    "_ = dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMvD4-9wXy_1"
   },
   "source": [
    "Review of the performance of the model on the validation/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "YAcO31dIX7JE",
    "outputId": "797a7c84-5c1c-4ec8-c75e-12c675ea8061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.9060402684563759\n",
      "Accuracy Score:   0.9873333333333333\n",
      "Precision Score:  0.9642857142857143\n",
      "F1 Score:         0.9342560553633219\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with RandomForest (using default parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, RandomeForestClassifier has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* n_estimators: The number of trees in the forsest\n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is 100.  \n",
    "* max_depth: The maximum depth per tree. \n",
    "    - Deeper trees might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is None, which allows the tree to grow without constraint.\n",
    "* See the SciKit Learn documentation for more details. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = rforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rforest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.8456375838926175\n",
      "Accuracy Score:   0.9833333333333333\n",
      "Precision Score:  0.984375\n",
      "F1 Score:         0.9097472924187726\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.41677974 0.63753957 0.09050204 0.54975124 0.00909091 0.5226142\n",
      " 0.19611036 0.10560832 0.2627318         nan 0.05422886 0.09638173\n",
      " 0.09651741 0.00909091 0.05454545 0.55590231 0.06037992 0.08141113\n",
      " 0.29606513 0.06625961 0.01818182 0.31705111 0.06951606 0.13595658\n",
      " 0.05151515 0.80660335 0.34120308 0.0813659  0.31402081 0.14762551\n",
      " 0.05454545 0.15712347 0.16621438 0.12985075 0.11474446 0.61022162\n",
      " 0.07838082 0.09041158 0.61320669 0.00606061 0.0030303  0.09050204\n",
      " 0.3624152  0.04825871 0.01818182        nan 0.         0.01492537\n",
      " 0.07232022 0.30497512 0.06028946 0.20520127 0.         0.10863863\n",
      " 0.         0.22351877 0.08747173 0.02424242 0.00909091 0.\n",
      " 0.1116237  0.37173225 0.69782904 0.41374943 0.04830393 0.0030303\n",
      " 0.03934871 0.00909091 0.09045681 0.3987336  0.0030303  0.\n",
      " 0.03939394 0.02121212 0.05454545 0.060199   0.28059701 0.03030303\n",
      " 0.45612845 0.02121212 0.         0.02121212 0.04206242 0.03030303\n",
      " 0.06947083 0.0605156  0.09050204 0.19588422 0.0332881  0.22953415\n",
      " 0.02424242 0.24161013 0.73410222 0.72799638 0.35938489 0.46811398\n",
      " 0.12695613 0.0030303  0.         0.01515152 0.08141113 0.0541384\n",
      " 0.61338761 0.09045681 0.11754862 0.28095884 0.05753053 0.12383537\n",
      " 0.40171868 0.39579376 0.0030303  0.0030303  0.41379466 0.09045681\n",
      " 0.43794663 0.10253279 0.06621438 0.         0.03030303 0.10253279\n",
      " 0.15970149 0.66463139 0.14192673 0.         0.67973768 0.69782904\n",
      " 0.38665762 0.72501131 0.         0.03030303 0.14197196 0.03319765\n",
      " 0.0030303  0.09045681 0.07833559 0.46227951 0.65563094 0.0421981\n",
      " 0.00909091 0.28091361 0.07530529 0.34436906 0.44694708 0.64654003\n",
      " 0.03613749 0.6464948  0.18738128 0.04807779 0.50144731 0.37747626\n",
      " 0.38059701 0.01212121 0.12369968 0.23867028 0.35033921 0.\n",
      " 0.04518318 0.06928991 0.0030303  0.03030303 0.0694256  0.2627318\n",
      " 0.10868385 0.03030303 0.00606061 0.22641339 0.08141113 0.\n",
      " 0.13586612 0.10253279 0.02424242 0.16915423 0.26897332 0.01515152\n",
      " 0.07829037        nan 0.79746721 0.2627318  0.         0.38055179\n",
      " 0.52591588 0.0813659  0.06625961 0.03934871 0.03030303 0.27471732\n",
      " 0.01818182 0.05151515 0.41379466 0.0541384  0.04848485 0.338218\n",
      " 0.3501583  0.00909091 0.66770692 0.4893261  0.0030303  0.01818182\n",
      " 0.33817277 0.22351877 0.1116237  0.70999548 0.721981   0.28692899\n",
      " 0.09954772 0.05427408 0.13260968 0.27159656 0.07842605 0.11474446\n",
      " 0.04807779 0.18394392 0.         0.02121212 0.52559928 0.35029398\n",
      " 0.05734962 0.03939394 0.0874265  0.0724559  0.0421981  0.25974672\n",
      " 0.19045681 0.40786974 0.03636364 0.0571687  0.80348259 0.07535052\n",
      " 0.07236545 0.03631841 0.06322931 0.17222976 0.08444143 0.09045681\n",
      " 0.09954772 0.72207146 0.01515152 0.02727273 0.59823609 0.01212121\n",
      " 0.54373587 0.41668928 0.69787427 0.21424695 0.05431931 0.39565807\n",
      " 0.5256445  0.62523745 0.30818634 0.61316147 0.06625961 0.\n",
      " 0.06644052 0.0030303  0.19615559 0.30506558 0.06024423 0.02424242\n",
      " 0.09656264 0.03030303 0.01818182 0.09348711 0.04224333 0.0511081\n",
      " 0.         0.13586612 0.         0.00909091 0.16291271 0.37155133\n",
      " 0.03636364 0.03636364 0.81858887 0.0843962  0.03333333 0.04201719\n",
      " 0.07530529 0.06630484 0.07535052 0.07535052 0.06345545 0.\n",
      " 0.05712347 0.00606061 0.06322931 0.         0.77322479 0.\n",
      " 0.04807779 0.08444143 0.09353234 0.07539575 0.37453641 0.01795568\n",
      " 0.         0.38683853 0.19918589 0.04545455 0.0030303  0.31103573\n",
      " 0.10257802 0.0272275  0.35336952 0.10538218 0.38647671        nan\n",
      " 0.3232474  0.20850294 0.09050204 0.06928991 0.16906377 0.33532338\n",
      " 0.32614202 0.32302126 0.06625961 0.10565355 0.11754862 0.06625961\n",
      " 0.61031208 0.66160109 0.32003618 0.27788331 0.31393035 0.49543193\n",
      " 0.01212121 0.28977838 0.5226142  0.63749435 0.55884215 0.08435097\n",
      " 0.05151515 0.45300769 0.11171416 0.08747173 0.03030303 0.06327454\n",
      " 0.08751696 0.50144731 0.07838082 0.03030303 0.2415649  0.07232022\n",
      " 0.03030303 0.59828132 0.09651741 0.38661239 0.61311624 0.08141113\n",
      " 0.28394392 0.04830393 0.07548621 0.44418815 0.         0.\n",
      " 0.1085934  0.61334238 0.25671642 0.09941203 0.60723654 0.07842605\n",
      " 0.67684306 0.32306649 0.49561284 0.01515152 0.00606061 0.06621438\n",
      " 0.41994573 0.04848485 0.07535052 0.0571687  0.         0.45590231\n",
      " 0.         0.09954772 0.1418815  0.68281321 0.         0.43188602\n",
      " 0.07838082 0.20818634 0.32908186 0.29611036 0.060199   0.27177748\n",
      " 0.00606061 0.03631841 0.01818182 0.10551787 0.07838082 0.21460877\n",
      " 0.06928991 0.01515152 0.         0.40479421 0.04807779 0.\n",
      " 0.06359114 0.04504749 0.03636364 0.44405246 0.06653098 0.41071913\n",
      " 0.11139756        nan 0.07548621 0.13867028 0.03595658 0.00606061\n",
      " 0.03333333 0.08738128 0.06037992 0.7339213  0.51058345 0.17530529\n",
      " 0.05146992        nan 0.72211669 0.09651741 0.09950249 0.00606061\n",
      " 0.04848485 0.00606061 0.31108096 0.41967436 0.50167345 0.06928991\n",
      " 0.         0.12686567 0.05128901 0.14486658 0.08141113 0.32921755\n",
      " 0.20854817 0.07232022 0.35323383 0.24758028 0.04504749 0.06928991\n",
      " 0.18403437 0.31402081 0.11442786 0.39864315 0.35029398 0.02121212\n",
      " 0.08444143 0.12369968 0.07838082 0.054455   0.04848485 0.\n",
      " 0.00909091 0.53776572 0.02424242 0.10863863 0.26259611 0.29606513\n",
      " 0.09050204 0.13862506 0.01818182 0.09348711 0.1933062  0.14798734\n",
      " 0.39258254        nan 0.07838082 0.06947083 0.73107191 0.47729534\n",
      " 0.0571687  0.10854817        nan 0.09959294 0.2687924  0.45915875\n",
      " 0.16295794 0.0571687  0.67091814 0.10257802 0.08453189 0.04843962\n",
      " 0.51356852 0.17819991 0.64350972 0.00606061 0.03310719 0.02424242\n",
      " 0.44396201 0.0541384  0.         0.09348711 0.0663953  0.\n",
      " 0.05739484 0.75531434 0.05128901 0.07833559 0.40171868 0.35033921\n",
      " 0.13288105 0.78245138]\n",
      "  warnings.warn(\n",
      "/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the train scores are non-finite: [4.40328759e-01 6.82018296e-01 6.87307033e-02 5.87632933e-01\n",
      " 2.18953688e-02 5.66429388e-01 2.00934820e-01 1.23825043e-01\n",
      " 2.83950829e-01            nan 5.36277873e-02 1.17810177e-01\n",
      " 1.10283019e-01 1.13207547e-02 6.71698113e-02 6.01946827e-01\n",
      " 7.02172670e-02 8.45797599e-02 3.08867925e-01 6.64665523e-02\n",
      " 1.88679245e-02 3.30803316e-01 7.85162950e-02 1.57787307e-01\n",
      " 5.58490566e-02 8.67041166e-01 3.58759291e-01 7.09948542e-02\n",
      " 3.43644940e-01 1.69977130e-01 7.47169811e-02 1.77412807e-01\n",
      " 1.89485420e-01 1.66089194e-01 1.13259005e-01 6.53310463e-01\n",
      " 8.15580332e-02 9.21269297e-02 6.65408805e-01 3.01886792e-03\n",
      " 9.81132075e-03 9.96740995e-02 3.88945111e-01 5.96540881e-02\n",
      " 1.20754717e-02            nan 0.00000000e+00 8.33333333e-03\n",
      " 9.06174957e-02 3.31549457e-01 5.74013722e-02 2.23599200e-01\n",
      " 0.00000000e+00 1.20051458e-01 0.00000000e+00 2.52226987e-01\n",
      " 9.28816467e-02 3.47169811e-02 9.05660377e-03 0.00000000e+00\n",
      " 1.31392224e-01 3.97204117e-01 7.54528302e-01 4.62241281e-01\n",
      " 4.68124643e-02 7.54716981e-04 4.68067467e-02 2.11320755e-02\n",
      " 7.85620354e-02 4.13873642e-01 1.50943396e-03 2.26415094e-03\n",
      " 4.98113208e-02 3.47169811e-02 6.41509434e-02 4.30703259e-02\n",
      " 2.94585477e-01 4.15094340e-02 5.02269868e-01 2.94368210e-02\n",
      " 0.00000000e+00 3.92452830e-02 4.68324757e-02 4.07547170e-02\n",
      " 9.13579188e-02 7.09576901e-02 8.08061750e-02 2.34208119e-01\n",
      " 4.22784448e-02 2.54473985e-01 4.30188679e-02 2.56029160e-01\n",
      " 7.72652945e-01 7.99079474e-01 3.83687822e-01 5.10560320e-01\n",
      " 1.46466552e-01 1.50943396e-03 0.00000000e+00 2.49056604e-02\n",
      " 8.38250429e-02 5.66552316e-02 6.47252716e-01 9.13722127e-02\n",
      " 1.38979417e-01 3.12647227e-01 7.39765580e-02 1.52504288e-01\n",
      " 4.20706118e-01 4.29725557e-01 1.50943396e-03 3.77358491e-03\n",
      " 4.44093768e-01 9.96769583e-02 4.73539165e-01 1.09505432e-01\n",
      " 6.04288165e-02 0.00000000e+00 3.54716981e-02 1.01952544e-01\n",
      " 1.72272727e-01 7.29596913e-01 1.67618639e-01 0.00000000e+00\n",
      " 7.28850772e-01 7.53770726e-01 4.15380217e-01 7.83990852e-01\n",
      " 0.00000000e+00 3.16981132e-02 1.75900515e-01 2.49170955e-02\n",
      " 1.50943396e-03 9.66552316e-02 8.76043453e-02 5.11312178e-01\n",
      " 6.91092053e-01 4.30445969e-02 1.13207547e-02 2.92278445e-01\n",
      " 6.34476844e-02 3.57226987e-01 4.77318468e-01 7.04668382e-01\n",
      " 3.09719840e-02 6.85042882e-01 2.04591195e-01 4.15608919e-02\n",
      " 5.36958262e-01 4.13873642e-01 4.19905660e-01 1.50943396e-02\n",
      " 1.13264723e-01 2.58990852e-01 3.82169811e-01 0.00000000e+00\n",
      " 5.13579188e-02 6.94825615e-02 1.50943396e-03 3.24528302e-02\n",
      " 7.55031447e-02 2.74905660e-01 1.08730703e-01 4.75471698e-02\n",
      " 1.88679245e-02 2.34877073e-01 8.38250429e-02 0.00000000e+00\n",
      " 1.41958262e-01 9.89251001e-02 2.71698113e-02 1.99305317e-01\n",
      " 2.83930818e-01 2.79245283e-02 7.92967410e-02            nan\n",
      " 8.55737564e-01 2.66603774e-01 0.00000000e+00 4.10840480e-01\n",
      " 6.01872499e-01 8.08061750e-02 6.49571184e-02 4.60577473e-02\n",
      " 2.79245283e-02 3.19514008e-01 2.26415094e-02 6.71698113e-02\n",
      " 4.39559748e-01 5.74099485e-02 5.50943396e-02 3.55714694e-01\n",
      " 3.73096055e-01 9.05660377e-03 7.19785592e-01 5.24908519e-01\n",
      " 9.81132075e-03 2.03773585e-02 3.60248714e-01 2.75651801e-01\n",
      " 1.14022298e-01 7.59053745e-01 7.62827330e-01 3.11152087e-01\n",
      " 9.28816467e-02 6.41909663e-02 1.58582047e-01 2.90820469e-01\n",
      " 7.47455689e-02 1.16275014e-01 4.45797599e-02 2.05485992e-01\n",
      " 0.00000000e+00 2.26500858e-02 5.62675815e-01 3.72344197e-01\n",
      " 6.34105203e-02 4.15094340e-02 9.74299600e-02 8.07918811e-02\n",
      " 4.38050314e-02 2.92241281e-01 2.21978273e-01 4.63676387e-01\n",
      " 3.62264151e-02 4.68439108e-02 8.67066895e-01 8.15608919e-02\n",
      " 6.41938250e-02 3.85077187e-02 5.21269297e-02 2.23470555e-01\n",
      " 7.77873070e-02 9.36363636e-02 1.04957118e-01 7.85480274e-01\n",
      " 2.11320755e-02 3.54716981e-02 6.52550029e-01 9.05660377e-03\n",
      " 6.10263007e-01 4.56200686e-01 7.37913093e-01 2.31881075e-01\n",
      " 5.73870783e-02 4.19133791e-01 5.61183533e-01 6.69968553e-01\n",
      " 3.08116066e-01 6.58616352e-01 5.21269297e-02 0.00000000e+00\n",
      " 7.55002859e-02 3.77358491e-03 2.14473985e-01 3.24734134e-01\n",
      " 6.64636935e-02 3.47169811e-02 9.81646655e-02 3.39622642e-02\n",
      " 2.64150943e-02 1.00445969e-01 4.07804460e-02 4.00514580e-02\n",
      " 0.00000000e+00 1.38942253e-01 0.00000000e+00 1.13207547e-02\n",
      " 1.87287021e-01 3.81380789e-01 3.62349914e-02 6.11320755e-02\n",
      " 8.89719840e-01 8.30703259e-02 3.84905660e-02 2.94854202e-02\n",
      " 7.77958834e-02 7.77873070e-02 7.40137221e-02 7.25042882e-02\n",
      " 7.85162950e-02 2.27272727e-03 4.91080617e-02 1.88679245e-02\n",
      " 7.02401372e-02 0.00000000e+00 8.40626072e-01 1.50943396e-03\n",
      " 5.21269297e-02 7.92967410e-02 8.83533448e-02 9.21154946e-02\n",
      " 4.10111492e-01 1.21069182e-02 0.00000000e+00 4.04019440e-01\n",
      " 2.48467696e-01 5.66037736e-02 9.81132075e-03 3.20974843e-01\n",
      " 1.04202401e-01 2.64322470e-02 3.90457404e-01 9.36535163e-02\n",
      " 3.87449971e-01            nan 3.60974843e-01 2.37121212e-01\n",
      " 8.23184677e-02 6.72212693e-02 1.97104059e-01 3.57204117e-01\n",
      " 3.39862779e-01 3.54977130e-01 5.58976558e-02 9.74099485e-02\n",
      " 1.26169240e-01 6.26929674e-02 6.49551172e-01 7.16006289e-01\n",
      " 3.23230417e-01 2.91509434e-01 3.19465409e-01 5.75520297e-01\n",
      " 2.26415094e-02 3.27790166e-01 5.87581475e-01 6.82024014e-01\n",
      " 6.21618067e-01 7.55231561e-02 6.79273871e-02 5.06032018e-01\n",
      " 1.37409949e-01 8.68439108e-02 4.52830189e-02 6.94825615e-02\n",
      " 1.01938250e-01 5.52126930e-01 7.92967410e-02 3.47169811e-02\n",
      " 2.44694111e-01 5.59005146e-02 3.16981132e-02 6.72938822e-01\n",
      " 9.51600915e-02 4.24436821e-01 6.52581475e-01 8.53344768e-02\n",
      " 3.01340766e-01 4.60520297e-02 8.53201830e-02 4.56901086e-01\n",
      " 0.00000000e+00 0.00000000e+00 1.18544883e-01 6.59342481e-01\n",
      " 2.89262436e-01 1.04988565e-01 6.69182390e-01 9.28787879e-02\n",
      " 7.37887364e-01 3.54959977e-01 5.54311035e-01 2.41509434e-02\n",
      " 1.88679245e-02 6.42024014e-02 4.69008005e-01 6.03773585e-02\n",
      " 7.77844483e-02 4.38250429e-02 0.00000000e+00 4.72066895e-01\n",
      " 0.00000000e+00 1.10994854e-01 1.51789594e-01 7.51506575e-01\n",
      " 0.00000000e+00 4.63753573e-01 8.00514580e-02 2.25080046e-01\n",
      " 3.39842767e-01 3.17146941e-01 6.42024014e-02 2.96063465e-01\n",
      " 6.79245283e-03 4.90623213e-02 1.73584906e-02 9.96998285e-02\n",
      " 8.08061750e-02 2.52958834e-01 6.04288165e-02 1.58490566e-02\n",
      " 0.00000000e+00 4.40265866e-01 3.02401372e-02 0.00000000e+00\n",
      " 6.71841052e-02 3.62778731e-02 5.20754717e-02 4.67481418e-01\n",
      " 7.62349914e-02 4.49399657e-01 1.26123499e-01            nan\n",
      " 9.28702115e-02 1.37438536e-01 3.40137221e-02 1.81132075e-02\n",
      " 3.77358491e-02 8.38250429e-02 7.09748428e-02 7.78710692e-01\n",
      " 5.43027444e-01 2.11372213e-01 6.19096627e-02            nan\n",
      " 7.71126358e-01 1.26841052e-01 9.44110921e-02 3.01886792e-03\n",
      " 5.58490566e-02 1.96226415e-02 3.40617496e-01 4.41074900e-01\n",
      " 5.18061750e-01 7.32590051e-02 0.00000000e+00 1.29108062e-01\n",
      " 6.04002287e-02 1.54088050e-01 8.38250429e-02 3.51929674e-01\n",
      " 2.55197256e-01 5.51457976e-02 3.76126358e-01 2.81692396e-01\n",
      " 4.53316181e-02 6.87307033e-02 2.16032018e-01 3.39113779e-01\n",
      " 1.08018868e-01 4.13130360e-01 3.74591195e-01 2.64150943e-02\n",
      " 8.60891938e-02 1.44982847e-01 7.92938822e-02 7.02001144e-02\n",
      " 6.26415094e-02 0.00000000e+00 1.13207547e-02 5.72478559e-01\n",
      " 2.86792453e-02 1.13259005e-01 3.08147513e-01 2.95280160e-01\n",
      " 9.36363636e-02 1.56380789e-01 1.58490566e-02 9.21297885e-02\n",
      " 2.02401372e-01 1.65363065e-01 4.18433391e-01            nan\n",
      " 7.32590051e-02 7.39937107e-02 7.74153802e-01 5.24162379e-01\n",
      " 6.49542596e-02 1.11769583e-01            nan 1.17032590e-01\n",
      " 2.82452830e-01 5.31692396e-01 1.53287593e-01 5.74070898e-02\n",
      " 7.25028588e-01 1.22332762e-01 8.98513436e-02 5.73727844e-02\n",
      " 5.21112064e-01 2.09119497e-01 6.76735277e-01 1.88679245e-02\n",
      " 3.24842767e-02 3.47169811e-02 4.61455117e-01 5.51457976e-02\n",
      " 2.26415094e-03 1.05731847e-01 7.39965695e-02 0.00000000e+00\n",
      " 7.55002859e-02 8.18702115e-01 5.96455117e-02 8.76043453e-02\n",
      " 4.34245283e-01 3.61772441e-01 1.67598628e-01 8.38353345e-01]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.8185888738127544\n",
      "... with parameters: {'n_estimators': 112, 'min_samples_split': 36, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0006000000000000001, 'max_depth': 12, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,50),  \n",
    "    'min_samples_leaf': np.arange(1,40),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_depth': np.arange(1,50),\n",
    "    'n_estimators':np.arange(105,350),\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = rforest, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rand_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.785234899328859\n",
      "Accuracy Score:   0.9746666666666667\n",
      "Precision Score:  0.9512195121951219\n",
      "F1 Score:         0.8602941176470589\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest_randomsearch_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with ADABoost (using default parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, ADABoostClassifier has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* max_depth: The maximum depth per tree. \n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is None (meaning, the tree can grow to a point where all leaves have 1 observation).\n",
    "* learning_rate: The learning rate determines the step size at each iteration while your model optimizes toward its objective. \n",
    "    - A low learning rate makes computation slower, and requires more rounds to achieve the same reduction in residual error as a model with a high learning rate. But it optimizes the chances to reach the best optimum.\n",
    "    - Larger learning rates may not converge on a solution.\n",
    "    - The value must be between 0 and 1. Default is 0.3.\n",
    "* n_estimators: The number of trees in our ensemble. \n",
    "    - Equivalent to the number of boosting rounds.\n",
    "    - The value must be an integer greater than 0. Default is 100.\n",
    "* See the SciKit Learn documentation for more details. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "aboost = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = aboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = aboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.7248322147651006\n",
      "Accuracy Score:   0.9626666666666667\n",
      "Precision Score:  0.8780487804878049\n",
      "F1 Score:         0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aboost_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, GradientBoostingClassifier has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* max_depth: The maximum depth per tree. \n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is None (meaning, the tree can grow to a point where all leaves have 1 observation).\n",
    "* learning_rate: The learning rate determines the step size at each iteration while your model optimizes toward its objective. \n",
    "    - A low learning rate makes computation slower, and requires more rounds to achieve the same reduction in residual error as a model with a high learning rate. But it optimizes the chances to reach the best optimum.\n",
    "    - Larger learning rates may not converge on a solution.\n",
    "    - The value must be between 0 and 1. Default is 0.3.\n",
    "* n_estimators: The number of trees in our ensemble. \n",
    "    - Equivalent to the number of boosting rounds.\n",
    "    - The value must be an integer greater than 0. Default is 100.\n",
    "* See the SciKit Learn documentation for more details. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = gboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.8657718120805369\n",
      "Accuracy Score:   0.9826666666666667\n",
      "Precision Score:  0.9555555555555556\n",
      "F1 Score:         0.9084507042253522\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, XGBoost has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* max_depth: The maximum depth per tree. \n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is 6.\n",
    "* learning_rate: The learning rate determines the step size at each iteration while your model optimizes toward its objective. \n",
    "    - A low learning rate makes computation slower, and requires more rounds to achieve the same reduction in residual error as a model with a high learning rate. But it optimizes the chances to reach the best optimum.\n",
    "    - The value must be between 0 and 1. Default is 0.3.\n",
    "* n_estimators: The number of trees in our ensemble. \n",
    "    - Equivalent to the number of boosting rounds.\n",
    "    - The value must be an integer greater than 0. Default is 100.\n",
    "* colsample_bytree: Represents the fraction of columns to be randomly sampled for each tree. \n",
    "    - It might improve overfitting.\n",
    "    - The value must be between 0 and 1. Default is 1.\n",
    "* subsample: Represents the fraction of observations to be sampled for each tree. \n",
    "    - A lower values prevent overfitting but might lead to under-fitting.\n",
    "    - The value must be between 0 and 1. Default is 1.\n",
    "* See the XGBoost documentation for more details. https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/sudeepkakarla/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:31:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "_ = xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.8926174496644296\n",
      "Accuracy Score:   0.9853333333333333\n",
      "Precision Score:  0.9568345323741008\n",
      "F1 Score:         0.9236111111111113\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Summarize results    \n",
    "\n",
    "As usual -- in this section you provide a recap your approach, results, and discussion of findings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall scores...\n",
      "Decision Tree:    0.9060402684563759\n",
      "Random Forest:    0.8456375838926175\n",
      "Ada Boosted Tree: 0.7248322147651006\n",
      "Gradient Tree:    0.8657718120805369\n",
      "XGBoost Tree:     0.8926174496644296\n",
      "Random Forest with Random Search:0.785234899328859\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall scores...\")\n",
    "print(f\"{'Decision Tree:':18}{dtree_recall}\")\n",
    "print(f\"{'Random Forest:':18}{rforest_recall}\")\n",
    "print(f\"{'Ada Boosted Tree:':18}{aboost_recall}\")\n",
    "print(f\"{'Gradient Tree:':18}{gboost_recall}\")\n",
    "print(f\"{'XGBoost Tree:':18}{xgboost}\")\n",
    "print(f\"{'Random Forest with Random Search:':18}{rforest_randomsearch_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When we compare models Random forest and Random forest with Random Search we observe that the Random Forest has more recall socres.\n",
    "#This can draw us an interpretation that random forest is a better model here. \n",
    "#We know the more recall score the better the model is.\n",
    "#And over all the decision tree is the best one amongst the others.\n",
    "#optimal addittional parameters can also improve the model."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Class08b-decision_tree_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
